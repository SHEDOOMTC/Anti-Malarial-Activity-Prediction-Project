{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34de9f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing molecules and generating features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33208/33208 [05:23<00:00, 102.73it/s]\n",
      "c:\\Users\\USER\\OneDrive\\Desktop\\AI Projects\\Anti-Malarial-Activity-Prediction-Project\\env\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 - Train Loss: 0.6934 - Test ROC AUC: 0.5619 - Test PR AUC: 0.5840\n",
      "Epoch 02 - Train Loss: 0.6933 - Test ROC AUC: 0.5355 - Test PR AUC: 0.5317\n",
      "Epoch 03 - Train Loss: 0.6932 - Test ROC AUC: 0.4980 - Test PR AUC: 0.5176\n",
      "Epoch 04 - Train Loss: 0.6931 - Test ROC AUC: 0.5120 - Test PR AUC: 0.5213\n",
      "Epoch 05 - Train Loss: 0.6928 - Test ROC AUC: 0.5274 - Test PR AUC: 0.5308\n",
      "Epoch 06 - Train Loss: 0.6920 - Test ROC AUC: 0.5184 - Test PR AUC: 0.5216\n",
      "Epoch 07 - Train Loss: 0.6919 - Test ROC AUC: 0.5191 - Test PR AUC: 0.5207\n",
      "Epoch 08 - Train Loss: 0.6919 - Test ROC AUC: 0.5232 - Test PR AUC: 0.5219\n",
      "Epoch 09 - Train Loss: 0.6918 - Test ROC AUC: 0.5201 - Test PR AUC: 0.5213\n",
      "Epoch 10 - Train Loss: 0.6917 - Test ROC AUC: 0.5214 - Test PR AUC: 0.5216\n",
      "Epoch 11 - Train Loss: 0.6916 - Test ROC AUC: 0.5211 - Test PR AUC: 0.5217\n",
      "Epoch 12 - Train Loss: 0.6915 - Test ROC AUC: 0.5212 - Test PR AUC: 0.5208\n",
      "Epoch 13 - Train Loss: 0.6915 - Test ROC AUC: 0.5200 - Test PR AUC: 0.5210\n",
      "Epoch 14 - Train Loss: 0.6913 - Test ROC AUC: 0.5227 - Test PR AUC: 0.5218\n",
      "Epoch 15 - Train Loss: 0.6917 - Test ROC AUC: 0.5215 - Test PR AUC: 0.5246\n",
      "Epoch 16 - Train Loss: 0.6916 - Test ROC AUC: 0.5254 - Test PR AUC: 0.5305\n",
      "Epoch 17 - Train Loss: 0.6914 - Test ROC AUC: 0.5205 - Test PR AUC: 0.5265\n",
      "Epoch 18 - Train Loss: 0.6913 - Test ROC AUC: 0.5153 - Test PR AUC: 0.5255\n",
      "Epoch 19 - Train Loss: 0.6914 - Test ROC AUC: 0.5007 - Test PR AUC: 0.5217\n",
      "Epoch 20 - Train Loss: 0.6912 - Test ROC AUC: 0.5152 - Test PR AUC: 0.5200\n",
      "Epoch 21 - Train Loss: 0.6912 - Test ROC AUC: 0.5174 - Test PR AUC: 0.5207\n",
      "Epoch 22 - Train Loss: 0.6912 - Test ROC AUC: 0.5218 - Test PR AUC: 0.5218\n",
      "Epoch 23 - Train Loss: 0.6912 - Test ROC AUC: 0.5184 - Test PR AUC: 0.5209\n",
      "Epoch 24 - Train Loss: 0.6912 - Test ROC AUC: 0.5237 - Test PR AUC: 0.5235\n",
      "Epoch 25 - Train Loss: 0.6912 - Test ROC AUC: 0.5218 - Test PR AUC: 0.5219\n",
      "Epoch 26 - Train Loss: 0.6912 - Test ROC AUC: 0.5210 - Test PR AUC: 0.5215\n",
      "Epoch 27 - Train Loss: 0.6915 - Test ROC AUC: 0.5206 - Test PR AUC: 0.5211\n",
      "Epoch 28 - Train Loss: 0.6919 - Test ROC AUC: 0.5284 - Test PR AUC: 0.5307\n",
      "Epoch 29 - Train Loss: 0.6912 - Test ROC AUC: 0.5157 - Test PR AUC: 0.5247\n",
      "Epoch 30 - Train Loss: 0.6911 - Test ROC AUC: 0.5141 - Test PR AUC: 0.5226\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, rdMolDescriptors\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Data Preparation\n",
    "# ---------------------------\n",
    "\n",
    "def mol_to_graph_data_obj(mol):\n",
    "    \"\"\"Convert RDKit mol object to PyTorch Geometric Data object\"\"\"\n",
    "    # Node features: atomic number one-hot encoding (simplified here as atomic number)\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features.append([atom.GetAtomicNum()])\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "\n",
    "    # Edges\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])\n",
    "        # Bond type as edge feature (single=1, double=2, triple=3, aromatic=4)\n",
    "        bond_type = bond.GetBondType()\n",
    "        if bond_type == Chem.rdchem.BondType.SINGLE:\n",
    "            bt = 1\n",
    "        elif bond_type == Chem.rdchem.BondType.DOUBLE:\n",
    "            bt = 2\n",
    "        elif bond_type == Chem.rdchem.BondType.TRIPLE:\n",
    "            bt = 3\n",
    "        elif bond_type == Chem.rdchem.BondType.AROMATIC:\n",
    "            bt = 4\n",
    "        else:\n",
    "            bt = 0\n",
    "        edge_attr.append([bt])\n",
    "        edge_attr.append([bt])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    return data\n",
    "\n",
    "def get_rdkit_fingerprint(mol, fp_size=2048):\n",
    "    \"\"\"Generate RDKit Daylight-like fingerprint as numpy array\"\"\"\n",
    "    fp = Chem.RDKFingerprint(mol, fpSize=fp_size)\n",
    "    arr = np.zeros((fp_size,), dtype=int)\n",
    "    on_bits = list(fp.GetOnBits())\n",
    "    arr[on_bits] = 1\n",
    "    return arr\n",
    "\n",
    "# Load your dataset CSV with 'canonical_smiles' and 'label' columns\n",
    "df = pd.read_csv('../data/merged_dataset.csv')\n",
    "\n",
    "# Filter valid molecules\n",
    "valid_rows = []\n",
    "graph_data_list = []\n",
    "fingerprints = []\n",
    "labels = []\n",
    "\n",
    "print(\"Processing molecules and generating features...\")\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    smi = row['canonical_smiles']\n",
    "    label = row['activity_label']  # assuming binary label: 0 or 1\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is None:\n",
    "        continue\n",
    "    # Graph data\n",
    "    graph_data = mol_to_graph_data_obj(mol)\n",
    "    graph_data.y = torch.tensor([label], dtype=torch.float)\n",
    "    graph_data_list.append(graph_data)\n",
    "\n",
    "    # Fingerprint\n",
    "    fp = get_rdkit_fingerprint(mol)\n",
    "    fingerprints.append(fp)\n",
    "\n",
    "    labels.append(label)\n",
    "    valid_rows.append(idx)\n",
    "\n",
    "# Convert fingerprints to tensor\n",
    "fingerprints = torch.tensor(np.array(fingerprints), dtype=torch.float)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Dataset and DataLoader\n",
    "# ---------------------------\n",
    "\n",
    "# Split indices for train/test\n",
    "train_idx, test_idx = train_test_split(range(len(graph_data_list)), test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "train_graphs = [graph_data_list[i] for i in train_idx]\n",
    "test_graphs = [graph_data_list[i] for i in test_idx]\n",
    "\n",
    "train_fps = fingerprints[train_idx]\n",
    "test_fps = fingerprints[test_idx]\n",
    "\n",
    "train_labels = torch.tensor([labels[i] for i in train_idx], dtype=torch.float)\n",
    "test_labels = torch.tensor([labels[i] for i in test_idx], dtype=torch.float)\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. FP-GNN Model Definition\n",
    "# ---------------------------\n",
    "\n",
    "class FP_GNN(nn.Module):\n",
    "    def __init__(self, fp_dim=2048, gnn_hidden_dim=128, fp_hidden_dim=128, out_dim=1):\n",
    "        super(FP_GNN, self).__init__()\n",
    "        # GNN layers (Graph Attention Network)\n",
    "        self.conv1 = GATConv(in_channels=1, out_channels=gnn_hidden_dim, heads=4, concat=True)\n",
    "        self.conv2 = GATConv(in_channels=gnn_hidden_dim*4, out_channels=gnn_hidden_dim, heads=4, concat=False)\n",
    "        \n",
    "        # Fingerprint MLP\n",
    "        self.fp_mlp = nn.Sequential(\n",
    "            nn.Linear(fp_dim, fp_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fp_hidden_dim, fp_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Combined MLP\n",
    "        self.combined_mlp = nn.Sequential(\n",
    "            nn.Linear(gnn_hidden_dim + fp_hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, out_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data, fp):\n",
    "        # data: PyG batch object with x, edge_index, edge_attr, batch\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # GNN forward\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Global pooling (mean)\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "        \n",
    "        # Fingerprint forward\n",
    "        fp_emb = self.fp_mlp(fp)\n",
    "        \n",
    "        # Concatenate graph and fingerprint embeddings\n",
    "        combined = torch.cat([x, fp_emb], dim=1)\n",
    "        \n",
    "        out = self.combined_mlp(combined)\n",
    "        return out.squeeze(1)  # output shape: (batch_size,)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Training and Evaluation Functions\n",
    "# ---------------------------\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = FP_GNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train_epoch(model, loader, fps, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        batch_fp = fps[i*loader.batch_size : i*loader.batch_size + batch.num_graphs].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch, batch_fp)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, fps, labels):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for i, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        batch_fp = fps[i*loader.batch_size : i*loader.batch_size + batch.num_graphs].to(device)\n",
    "        out = model(batch, batch_fp)\n",
    "        preds.append(torch.sigmoid(out).cpu())\n",
    "        trues.append(batch.y.cpu())\n",
    "    preds = torch.cat(preds).numpy()\n",
    "    trues = torch.cat(trues).numpy()\n",
    "    roc_auc = roc_auc_score(trues, preds)\n",
    "    pr_auc = average_precision_score(trues, preds)\n",
    "    return roc_auc, pr_auc\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Run Training and Evaluation\n",
    "# ---------------------------\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, train_fps, optimizer, criterion)\n",
    "    roc_auc, pr_auc = evaluate(model, test_loader, test_fps, test_labels)\n",
    "    print(f\"Epoch {epoch:02d} - Train Loss: {train_loss:.4f} - Test ROC AUC: {roc_auc:.4f} - Test PR AUC: {pr_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16039d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of Train loss over different epochs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_losses = []  # List to store loss values for each epoch\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, train_fps, optimizer, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Epoch {epoch} Loss: {train_loss:.4f}\")\n",
    "\n",
    "# After training, plot the train loss curve\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, marker='o', color='blue')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
