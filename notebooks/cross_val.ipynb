{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Step 2: Load combined features and labels\n",
    "X = np.load('../data/features_combined.npy')\n",
    "y = pd.read_csv('../data/labels.csv')  # assuming binary classification labels (0 or 1)\n",
    "\n",
    "# === Handle missing values ===\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# === Define models ===\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# === Scoring metrics ===\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# === Cross-validation setup ===\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# === Evaluate Random Forest ===\n",
    "print(\"\\nüîç Random Forest Cross-Validation (10-fold)\")\n",
    "rf_results = cross_validate(rf, X_imputed, y, cv=cv, scoring=scoring)\n",
    "for metric in scoring:\n",
    "    print(f\"{metric.capitalize()}: {np.mean(rf_results[f'test_{metric}']):.4f}\")\n",
    "\n",
    "# === Evaluate XGBoost ===\n",
    "print(\"\\nüîç XGBoost Cross-Validation (10-fold)\")\n",
    "xgb_results = cross_validate(xgb, X_imputed, y, cv=cv, scoring=scoring)\n",
    "for metric in scoring:\n",
    "    print(f\"{metric.capitalize()}: {np.mean(xgb_results[f'test_{metric}']):.4f}\")\n",
    "\n",
    "# === Optional: Train on full data and save models ===\n",
    "rf.fit(X_imputed, y)\n",
    "xgb.fit(X_imputed, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, auc, precision_recall_curve, confusion_matrix, \n",
    "    ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.calibration import calibration_curve\n",
    "import joblib\n",
    "\n",
    "# Load the Random Forest model\n",
    "rf_model = joblib.load('../models/random_forest_model.pkl')\n",
    "\n",
    "# Load the XGBoost model\n",
    "xgb_model = joblib.load('../models/xgboost_model.pkl')\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "xgb_probs = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 1. ROC Curve Comparison\n",
    "plt.figure(figsize=(10,6))\n",
    "RocCurveDisplay.from_estimator(rf_model, X_test, y_test, name='Random Forest')\n",
    "RocCurveDisplay.from_estimator(xgb_model, X_test, y_test, name='XGBoost')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Precision-Recall Curve\n",
    "plt.figure(figsize=(10,6))\n",
    "PrecisionRecallDisplay.from_estimator(rf_model, X_test, y_test, name='Random Forest')\n",
    "PrecisionRecallDisplay.from_estimator(xgb_model, X_test, y_test, name='XGBoost')\n",
    "plt.title('Precision-Recall Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Importance\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,6))\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "rf_importance = rf_model.feature_importances_\n",
    "sorted_idx = rf_importance.argsort()\n",
    "ax[0].barh(range(10), rf_importance[sorted_idx][-10:])\n",
    "ax[0].set_yticks(range(10))\n",
    "ax[0].set_yticklabels(X.columns[sorted_idx][-10:])\n",
    "ax[0].set_title('Random Forest - Top 10 Features')\n",
    "\n",
    "# XGBoost Feature Importance\n",
    "xgb_importance = xgb_model.feature_importances_\n",
    "sorted_idx = xgb_importance.argsort()\n",
    "ax[1].barh(range(10), xgb_importance[sorted_idx][-10:])\n",
    "ax[1].set_yticks(range(10))\n",
    "ax[1].set_yticklabels(X.columns[sorted_idx][-10:])\n",
    "ax[1].set_title('XGBoost - Top 10 Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Permutation Importance (More reliable)\n",
    "print(\"Calculating permutation importance...\")\n",
    "rf_result = permutation_importance(rf_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "xgb_result = permutation_importance(xgb_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,6))\n",
    "sorted_idx = rf_result.importances_mean.argsort()\n",
    "ax[0].boxplot(rf_result.importances[sorted_idx][-10:].T, vert=False,\n",
    "             labels=X.columns[sorted_idx][-10:])\n",
    "ax[0].set_title(\"Random Forest Permutation Importance\")\n",
    "\n",
    "sorted_idx = xgb_result.importances_mean.argsort()\n",
    "ax[1].boxplot(xgb_result.importances[sorted_idx][-10:].T, vert=False,\n",
    "             labels=X.columns[sorted_idx][-10:])\n",
    "ax[1].set_title(\"XGBoost Permutation Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calibration Plots\n",
    "plt.figure(figsize=(10,6))\n",
    "for name, probs in [('RF', rf_probs), ('XGB', xgb_probs)]:\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_test, probs, n_bins=10)\n",
    "    plt.plot(mean_predicted_value, fraction_of_positives, marker='o', label=name)\n",
    "plt.plot([0, 1], [0, 1], 'k:', label='Perfectly calibrated')\n",
    "plt.title('Calibration Plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
