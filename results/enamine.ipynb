{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   name                               smiles\n",
      "0  None        Cc1nc2sc3c(c2c(=O)[nH]1)CCCC3\n",
      "1  None         O=C(O)c1ccccc1SCC(=O)N1CCCC1\n",
      "2  None  O=C(O)c1ccccc1NS(=O)(=O)c1ccc(F)cc1\n",
      "3  None     Cc1nc2sc(-c3ccccc3)cc2c(=O)[nH]1\n",
      "4  None       CC(=O)c1ccc(Nc2nc3ccccc3s2)cc1\n",
      "Saved extracted Enamine data to ../data/enamine_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "# Load sdf files and merge\n",
    "\n",
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "\n",
    "def load_sdf_to_df(sdf_path):\n",
    "    suppl = Chem.SDMolSupplier(sdf_path)\n",
    "    records = []\n",
    "    for mol in suppl:\n",
    "        if mol is None:\n",
    "            continue\n",
    "        name = mol.GetProp('Name') if mol.HasProp('Name') else None\n",
    "        smiles = Chem.MolToSmiles(mol)\n",
    "        records.append({'name': name, 'smiles': smiles})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "df1 = load_sdf_to_df('../data/enamine_kinase_library.sdf')\n",
    "df2 = load_sdf_to_df('../data/enamine_hit_locator_library_460k.sdf')\n",
    "df3 = load_sdf_to_df('../data/enamine_dds_50k.sdf')\n",
    "\n",
    "df_enamine = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "df_enamine.drop_duplicates(subset='smiles', inplace=True)\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df_enamine.head())\n",
    "\n",
    "# Save extracted data to CSV\n",
    "csv_path = '../data/enamine_extracted.csv'\n",
    "df_enamine.to_csv(csv_path, index=False)\n",
    "print(f\"Saved extracted Enamine data to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Morgan fingerprints and descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing molecules: 100%|██████████| 553252/553252 [1:04:25<00:00, 143.13it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.47 GiB for an array with shape (553252, 2055) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m X_desc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(descriptor_features)\n\u001b[0;32m     64\u001b[0m \u001b[39m# Combine features\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m X_combined \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate([X_fp, X_desc], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     67\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature matrix shape: \u001b[39m\u001b[39m{\u001b[39;00mX_combined\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.47 GiB for an array with shape (553252, 2055) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# --- Step 1: Load dataset with SMILES ---\n",
    "\n",
    "df = pd.read_csv('../data/enamine_extracted.csv')  \n",
    "\n",
    "# --- Step 2: Initialize Morgan fingerprint generator ---\n",
    "generator = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "# --- Step 3: Define descriptor names and calculation functions ---\n",
    "\n",
    "descriptor_names = [\n",
    "    'MolWt', 'MolLogP', 'NumRotatableBonds',\n",
    "    'NumHAcceptors', 'NumHDonors', 'TPSA', 'RingCount'\n",
    "]\n",
    "\n",
    "def calc_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [np.nan] * len(descriptor_names)\n",
    "    return [\n",
    "        Descriptors.MolWt(mol),\n",
    "        Descriptors.MolLogP(mol),\n",
    "        Descriptors.NumRotatableBonds(mol),\n",
    "        Descriptors.NumHAcceptors(mol),\n",
    "        Descriptors.NumHDonors(mol),\n",
    "        Descriptors.TPSA(mol),\n",
    "        Descriptors.RingCount(mol)\n",
    "    ]\n",
    "\n",
    "def smiles_to_morgan_fp(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = generator.GetFingerprint(mol)\n",
    "    return np.array(fp)\n",
    "\n",
    "# --- Step 4: Generate features ---\n",
    "\n",
    "morgan_fps = []\n",
    "descriptor_features = []\n",
    "valid_indices = []\n",
    "\n",
    "print(\"Generating Morgan fingerprints and descriptors...\")\n",
    "for i, smi in enumerate(tqdm(df['smiles'], desc='Processing molecules')):\n",
    "    fp = smiles_to_morgan_fp(smi)\n",
    "    desc = calc_descriptors(smi)\n",
    "    if fp is not None and not any(np.isnan(desc)):\n",
    "        morgan_fps.append(fp)\n",
    "        descriptor_features.append(desc)\n",
    "        valid_indices.append(i)\n",
    "\n",
    "# Filter valid molecules\n",
    "df_valid = df.iloc[valid_indices].reset_index(drop=True)\n",
    "X_fp = np.array(morgan_fps, dtype=np.uint8)\n",
    "X_desc = np.array(descriptor_features)\n",
    "\n",
    "# Combine features\n",
    "X_combined = np.concatenate([X_fp, X_desc], axis=1)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting activity...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# --- Step 6: Predict and filter actives ---\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPredicting activity...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m predictions \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39mpredict(X_combined)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Map numeric predictions to labels\u001b[39;00m\n\u001b[0;32m     11\u001b[0m labels \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39minactive\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m p \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mactive\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m predictions]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_combined' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Load trained Random Forest model ---\n",
    "\n",
    "rf_model = joblib.load('../models/random_forest_model.pkl')  # Update path accordingly\n",
    "\n",
    "# --- Step 6: Predict and filter actives ---\n",
    "\n",
    "print(\"Predicting activity...\")\n",
    "predictions = rf_model.predict(X_combined)\n",
    "\n",
    "# Map numeric predictions to labels\n",
    "labels = ['inactive' if p == 0 else 'active' for p in predictions]\n",
    "\n",
    "# Add predicted labels to DataFrame\n",
    "df_valid['predicted_activity'] = labels\n",
    "\n",
    "# Filter to keep only predicted actives\n",
    "df_actives = df_valid[df_valid['predicted_activity'] == 'active']\n",
    "\n",
    "# Select relevant columns\n",
    "df_actives_filtered = df_actives[['name', 'smiles', 'predicted_activity']]\n",
    "\n",
    "# --- Step 7: Save results ---\n",
    "\n",
    "output_csv = '../data/predicted_enamine_actives.csv'\n",
    "df_actives_filtered.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Saved {len(df_actives_filtered)} predicted active compounds to '{output_csv}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# --- Step 4: Calculate descriptors ---\n",
    "descriptor_names = [\n",
    "    'MolWt', 'MolLogP', 'NumRotatableBonds',\n",
    "    'NumHAcceptors', 'NumHDonors', 'TPSA', 'RingCount'\n",
    "]\n",
    "\n",
    "def calc_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [np.nan] * len(descriptor_names)\n",
    "    return [\n",
    "        Descriptors.MolWt(mol),\n",
    "        Descriptors.MolLogP(mol),\n",
    "        Descriptors.NumRotatableBonds(mol),\n",
    "        Descriptors.NumHAcceptors(mol),\n",
    "        Descriptors.NumHDonors(mol),\n",
    "        Descriptors.TPSA(mol),\n",
    "        Descriptors.RingCount(mol)\n",
    "    ]\n",
    "\n",
    "print(\"Calculating descriptors for filtered compounds...\")\n",
    "desc_list = []\n",
    "for smi in tqdm(df_actives_filtered['smiles']):\n",
    "    desc_list.append(calc_descriptors(smi))\n",
    "\n",
    "df_desc = pd.DataFrame(desc_list, columns=descriptor_names)\n",
    "\n",
    "# --- Step 5: Combine descriptors with filtered dataframe ---\n",
    "df_filtered = df_actives_filtered.reset_index(drop=True)\n",
    "df_final = pd.concat([df_filtered, df_desc], axis=1)\n",
    "\n",
    "# --- Step 6: Apply Lipinski's Rule of 5 filter ---\n",
    "# Lipinski's rules:\n",
    "# - Molecular weight <= 500\n",
    "# - LogP <= 5\n",
    "# - Hydrogen bond donors <= 5\n",
    "# - Hydrogen bond acceptors <= 10\n",
    "\n",
    "lipinski_filter = (\n",
    "    (df_final['MolWt'] <= 500) &\n",
    "    (df_final['MolLogP'] <= 5) &\n",
    "    (df_final['NumHDonors'] <= 5) &\n",
    "    (df_final['NumHAcceptors'] <= 10)\n",
    ")\n",
    "\n",
    "df_lipinski = df_final[lipinski_filter].reset_index(drop=True)\n",
    "\n",
    "print(f\"Count after Lipinski's Rule of 5 filter: {len(df_lipinski)}\")\n",
    "\n",
    "# --- Step 7: Save the final filtered dataset ---\n",
    "output_path = '../data/filtered_enamine_actives.csv'\n",
    "df_lipinski.to_csv(output_path, index=False)\n",
    "print(f\"Final filtered dataset saved to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
