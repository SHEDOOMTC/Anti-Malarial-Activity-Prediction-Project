{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a468e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "from tqdm import tqdm\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4413d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import Datasets\n",
    "\n",
    "### import dataset from Coconut database\n",
    "coco = pd.read_csv(\"../../coconut_csv-06-2025.csv\", usecols=['identifier', 'canonical_smiles'])\n",
    "\n",
    "## Import dataset from the SuperNaT 3.0 database; then remove the rows where smiles are not available\n",
    "super = pd.read_csv(\"../../full_data_download.csv\", sep=';', usecols=['id', 'smiles'])\n",
    "super = super[super['smiles'].notnull()]\n",
    "\n",
    "## Import dataset from the Argentinan database\n",
    "Argen = pd.read_csv(\"../../NaturAr_query.csv\", usecols=['NatID', 'SMILES'])\n",
    "\n",
    "## import dataset from the Afrodabase; contains data in .smi and need to be converted to a df with the IDS and SMILES only retained\n",
    "file_path = '../../smiles_unique_all.smi'\n",
    "\n",
    "data = []\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # Split on the first whitespace only\n",
    "        parts = line.strip().split(maxsplit=1)\n",
    "        smiles = parts[0]\n",
    "        name = parts[1] if len(parts) > 1 else ''  # Handle lines with no name\n",
    "        data.append({'SMILES': smiles, 'ID': name})\n",
    "\n",
    "afro = pd.DataFrame(data)\n",
    "afro = afro[['ID', 'SMILES']]\n",
    "\n",
    "\n",
    "## rename all the headers to standardize and then concat the whole dataframe\n",
    "\n",
    "# Example renaming for each DataFrame\n",
    "coco = coco.rename(columns={coco.columns[0]: 'ID', coco.columns[1]: 'SMILES'})\n",
    "super = super.rename(columns={super.columns[0]: 'ID', super.columns[1]: 'SMILES'})\n",
    "Argen = Argen.rename(columns={Argen.columns[0]: 'ID', Argen.columns[1]: 'SMILES'})\n",
    "afro = afro.rename(columns={afro.columns[0]: 'ID', afro.columns[1]: 'SMILES'})\n",
    "\n",
    "\n",
    "## combine the data into single dataframe\n",
    "df = pd.concat([coco, super, Argen, afro], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461b0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we then canonize the smiles, removed all the NAN and duplicates to get a final compound list\n",
    "\n",
    "def canonicalize_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None  # invalid SMILES, skip\n",
    "    return Chem.MolToSmiles(mol, canonical=True)\n",
    "\n",
    "# Apply canonicalization, skipping invalid SMILES\n",
    "df['Canonical_SMILES'] = df['SMILES'].apply(canonicalize_smiles)\n",
    "\n",
    "# Drop rows where canonicalization failed (None values)\n",
    "filtered_df = df.dropna(subset=['Canonical_SMILES']).copy()\n",
    "\n",
    "# Replace original SMILES with canonical SMILES\n",
    "filtered_df['SMILES'] = filtered_df['Canonical_SMILES']\n",
    "\n",
    "# Remove duplicates based on canonical SMILES\n",
    "final_df = filtered_df.drop_duplicates(subset=['Canonical_SMILES'])\n",
    "\n",
    "# Drop the helper column if you want\n",
    "final_df = final_df.drop(columns=['Canonical_SMILES'])\n",
    "\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e76f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to Natural_product_cpds.csv\n"
     ]
    }
   ],
   "source": [
    "## then I save the file into a csv\n",
    "final_df.to_csv('../data/Natural_product_cpds.csv', index=False)\n",
    "print('saved to Natural_product_cpds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8678605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Morgan fingerprints and descriptors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing molecules:  17%|█▋        | 227808/1329645 [09:19<39:38, 463.16it/s]  [02:54:41] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:54:41] WARNING: not removing hydrogen atom without neighbors\n",
      "Processing molecules:  27%|██▋       | 357906/1329645 [18:35<39:00, 415.14it/s]  [03:03:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[03:03:57] WARNING: not removing hydrogen atom without neighbors\n",
      "Processing molecules:  29%|██▉       | 385569/1329645 [19:47<44:23, 354.39it/s][03:05:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[03:05:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[03:05:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[03:05:09] WARNING: not removing hydrogen atom without neighbors\n",
      "Processing molecules:  30%|██▉       | 398573/1329645 [20:42<1:40:19, 154.68it/s][03:06:04] Unusual charge on atom 37 number of radical electrons set to zero\n",
      "[03:06:04] Unusual charge on atom 37 number of radical electrons set to zero\n",
      "Processing molecules:  33%|███▎      | 433162/1329645 [24:06<1:16:27, 195.41it/s][03:09:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[03:09:28] WARNING: not removing hydrogen atom without neighbors\n",
      "Processing molecules: 100%|██████████| 1329645/1329645 [1:10:46<00:00, 313.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (1329645, 2055)\n"
     ]
    }
   ],
   "source": [
    "## it is time to generate descriptors and morgan fingerprints\n",
    "\n",
    "# --- Step 1: Load dataset with SMILES ---\n",
    "\n",
    "df = pd.read_csv('../data/Natural_product_cpds.csv')  # Replace with your dataset path\n",
    "\n",
    "# --- Step 2: Initialize Morgan fingerprint generator ---\n",
    "generator = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "\n",
    "# --- Step 3: Define descriptor names and calculation functions ---\n",
    "\n",
    "descriptor_names = [\n",
    "    'MolWt', 'MolLogP', 'NumRotatableBonds',\n",
    "    'NumHAcceptors', 'NumHDonors', 'TPSA', 'RingCount'\n",
    "]\n",
    "\n",
    "def calc_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [np.nan] * len(descriptor_names)\n",
    "    return [\n",
    "        Descriptors.MolWt(mol),\n",
    "        Descriptors.MolLogP(mol),\n",
    "        Descriptors.NumRotatableBonds(mol),\n",
    "        Descriptors.NumHAcceptors(mol),\n",
    "        Descriptors.NumHDonors(mol),\n",
    "        Descriptors.TPSA(mol),\n",
    "        Descriptors.RingCount(mol)\n",
    "    ]\n",
    "\n",
    "def smiles_to_morgan_fp(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    fp = generator.GetFingerprint(mol)\n",
    "    return np.array(fp)\n",
    "\n",
    "# --- Step 4: Generate features ---\n",
    "\n",
    "morgan_fps = []\n",
    "descriptor_features = []\n",
    "valid_indices = []\n",
    "\n",
    "print(\"Generating Morgan fingerprints and descriptors...\")\n",
    "for i, smi in enumerate(tqdm(df['SMILES'], desc='Processing molecules')):\n",
    "    fp = smiles_to_morgan_fp(smi)\n",
    "    desc = calc_descriptors(smi)\n",
    "    if fp is not None and not any(np.isnan(desc)):\n",
    "        morgan_fps.append(fp)\n",
    "        descriptor_features.append(desc)\n",
    "        valid_indices.append(i)\n",
    "\n",
    "# Filter valid molecules\n",
    "df_valid = df.iloc[valid_indices].reset_index(drop=True)\n",
    "X_fp = np.array(morgan_fps)\n",
    "X_desc = np.array(descriptor_features)\n",
    "\n",
    "# Combine features\n",
    "X_combined = np.concatenate([X_fp, X_desc], axis=1)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30b9691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting activity...\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5: Load trained Random Forest model ---\n",
    "\n",
    "rf_model = joblib.load('../models/random_forest_model.pkl')  # Update path accordingly\n",
    "\n",
    "# --- Step 6: Predict and filter actives ---\n",
    "\n",
    "print(\"Predicting activity...\")\n",
    "predictions = rf_model.predict(X_combined)\n",
    "\n",
    "# Map numeric predictions to labels\n",
    "labels = ['inactive' if p == 0 else 'active' for p in predictions]\n",
    "\n",
    "# Add predicted labels to DataFrame\n",
    "df_valid['predicted_activity'] = labels\n",
    "\n",
    "# Filter to keep only predicted actives\n",
    "df_actives = df_valid[df_valid['predicted_activity'] == 'active']\n",
    "\n",
    "# Select relevant columns\n",
    "df_actives_filtered = df_actives[['ID', 'SMILES', 'predicted_activity']]\n",
    "\n",
    "# --- Step 7: Save results ---\n",
    "\n",
    "##output_csv = '../data/predicted_actives.csv'\n",
    "##df_actives_filtered.to_csv(output_csv, index=False)\n",
    "\n",
    "##print(f\"Saved {len(df_actives_filtered)} predicted active compounds to '{output_csv}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a466e8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating descriptors for filtered compounds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 75696/343875 [01:19<06:48, 657.28it/s] [05:15:29] WARNING: not removing hydrogen atom without neighbors\n",
      " 24%|██▍       | 82138/343875 [01:29<08:44, 499.38it/s][05:15:39] Unusual charge on atom 37 number of radical electrons set to zero\n",
      "100%|██████████| 343875/343875 [07:01<00:00, 816.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count after Lipinski's Rule of 5 filter: 139743\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Calculate descriptors ---\n",
    "descriptor_names = [\n",
    "    'MolWt', 'MolLogP', 'NumRotatableBonds',\n",
    "    'NumHAcceptors', 'NumHDonors', 'TPSA', 'RingCount'\n",
    "]\n",
    "\n",
    "def calc_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return [np.nan] * len(descriptor_names)\n",
    "    return [\n",
    "        Descriptors.MolWt(mol),\n",
    "        Descriptors.MolLogP(mol),\n",
    "        Descriptors.NumRotatableBonds(mol),\n",
    "        Descriptors.NumHAcceptors(mol),\n",
    "        Descriptors.NumHDonors(mol),\n",
    "        Descriptors.TPSA(mol),\n",
    "        Descriptors.RingCount(mol)\n",
    "    ]\n",
    "\n",
    "print(\"Calculating descriptors for filtered compounds...\")\n",
    "desc_list = []\n",
    "for smi in tqdm(df_actives_filtered['SMILES']):\n",
    "    desc_list.append(calc_descriptors(smi))\n",
    "\n",
    "df_desc = pd.DataFrame(desc_list, columns=descriptor_names)\n",
    "\n",
    "# --- Step 5: Combine descriptors with filtered dataframe ---\n",
    "df_filtered = df_actives_filtered.reset_index(drop=True)\n",
    "df_final = pd.concat([df_filtered, df_desc], axis=1)\n",
    "\n",
    "# --- Step 6: Apply Lipinski's Rule of 5 filter ---\n",
    "# Lipinski's rules:\n",
    "# - Molecular weight <= 500\n",
    "# - LogP <= 5\n",
    "# - Hydrogen bond donors <= 5\n",
    "# - Hydrogen bond acceptors <= 10\n",
    "\n",
    "lipinski_filter = (\n",
    "    (df_final['MolWt'] <= 500) &\n",
    "    (df_final['MolLogP'] <= 5) &\n",
    "    (df_final['NumHDonors'] <= 5) &\n",
    "    (df_final['NumHAcceptors'] <= 10)\n",
    ")\n",
    "\n",
    "df_lipinski = df_final[lipinski_filter].reset_index(drop=True)\n",
    "\n",
    "print(f\"Count after Lipinski's Rule of 5 filter: {len(df_lipinski)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e0b209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final filtered dataset saved to: ../data/filtered_Natural_Product_actives.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Step 7: Save the final filtered dataset ---\n",
    "output_path = '../data/filtered_Natural_Product_actives.csv'\n",
    "df_lipinski.to_csv(output_path, index=False)\n",
    "print(f\"Final filtered dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5f064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
